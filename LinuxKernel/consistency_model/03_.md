# 并发问题
在计算机追寻计算性能的发展道路上，单核CPU性能遇到功耗墙，然后走向多核道路。在走上多核道路后，此前已经存在的单核CPU的性能优化方案给多核cpu带来了更复杂的挑战，这就是多核并发的挑战。
一致性
1. 写保证顺序性: 保证读之前的所有并发的写的结果是代码编写人员期望的末序（最后一个）写入的结果
2. 读保证可见性：保证上述写之后的结果对所有并发的读可见
3. 读/写都有原子性：
为了保证对同一共享变量读/写操作的原子性，我们需要将这一系列读/写操作打包放入 **(原子性)互斥** 的临界区中，让其不被调度打断，保证其 **原子性** 。这就需要我们进一步实现一系列同步原语（synchronization primitive）。通过使用这些同步原语，我们将能够构建多线程代码，以同步和受控的方式访问临界区。
## 1. 单核CPU上的优化导致的多核并发问题
假设我们希望通过代码（软件层面）实现同步原语，部分针对单核的一些优化手段会给同步原语的实现带来更多的挑战。
### 1.1. 编译优化
在1970年代，Frances E. Allen和 John Cocke一起提出了一种称为"规则依赖分析"（Dependency Analysis）的编译器优化技术。该技术可以自动识别程序中的数据依赖关系，并利用这些信息在不影响程序执行结果的前提下（eventually consistency），来进行指令重排和其他优化。通过减少数据相关性依赖，使得指令执行时减少（指令流水线中的取存阶段的）等待时间以及提升分支预测准确率。编译优化分为两个方面。
- 一方面，识别数据依赖关系时，编译器会默认指令访问的内存为当前指令序列独占。这大多数情况下优化的效果是读写操作的压缩，将多次内存的读/写压缩为单次的读/写和计算时的寄存器操作。当多核情况下，就会导致原本在某一个核心A的读/写之间的另一个核心B的读写在指令执行时放到了A读/写之外（**有序性**被破坏）。
```C
int lock()
{
  while (!done);
}

// 编译优化后，代码逻辑变成了这样。原本其他线程在lock线程两次读done变量之间的写就不可能发生了导致了lock不可能实现。
int lock()
{
  if (!done) while (1);
}
```
- 另一方面，指令重排会使得编译后的机器指令并不完全按照程序编写人员编写的代码逻辑顺序执行，这部分和指令优化相似不过是层级不同（一个是多条指令的顺序，一个是多条指令中的micro指令的顺寻）。
### 1.1.1. 编译优化导致的并发问题解决方法
主要是打破内存独占的假设，告诉编译器内存可能在指令之间被修改，使得编译器对依赖这部分内存的指令不优化
- 方法1：插入 “不可优化” 代码
``` C
// “Clobbers memory”
asm volatile ("" ::: "memory");
```
- 方法2：标记变量 load/store 为不可优化: 
``` C
// 使用 volatile 变量
extern int volatile done;
while (!done) ;
```
### 1.2. 指令优化导致的并发问题解决方法
经过编译优化后的指令在处理器上执行。处理器将一部分数据相关性的问题带到硬件设计中解决，通过数据无关的指令并行执行以提高效率。 现代乱序处理器中单个逻辑CPU中指令首先被处理器前端译码，然后被分派到各自的处理管线中执行，cpu中有多条处理管线同时运行，也就是说多条指令在多条流水线上并行执行。与编译优化类似，乱序执行受限于上述的数据依赖关系，不会影响程序执行的结果。但多核场景下，会导致多条读/写指令的**有序性**被破坏。
``` C
int x = 0;
int done = 1;
int thread_N(int n)
{
  // require
  while (done != 1);
  done = 0;
  x = n;
  print(x);
  // release 
  done = 1;
}
```
比如上述函数，done用于保证对共享变量x的读/写操作的临界区的原子性。如果`done = 0;`先执行
### 1.3. 缓存优化
为了填补cpu速度与内存存取速度的鸿沟，cpu提出了多级存储架构。在多数现代处理器架构中，每个逻辑cpu有自己的本地cache。
## 2. 解决方法 
1. 编译顺序一致性: 编译屏障
指令乱序执行顺序一致性: 内存屏障
缓存一致性: 读写屏障
## 最终解决方法————锁

## 参考
0. chatgpt
1. [编译器架构历史](https://en.wikipedia.org/wiki/History_of_compiler_construction)


## 例子
读写指令穿插